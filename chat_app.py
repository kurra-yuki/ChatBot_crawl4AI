import streamlit as st
from dotenv import load_dotenv
import os

from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.chains import RetrievalQA

# .envã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

st.title("ãƒ©ã‚·ã‚­ã‚¢ç ”ç©¶å®¤ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ ğŸ¤–")
query = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

# ãƒ™ã‚¯ãƒˆãƒ«DBãƒ­ãƒ¼ãƒ‰
embedding = OpenAIEmbeddings(openai_api_key=os.getenv("OPENAI_API_KEY"))
db = Chroma(persist_directory="lanet_chroma_md", embedding_function=embedding)

# ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã¨RAGãƒã‚§ãƒ¼ãƒ³ã®è¨­å®š
llm = ChatOpenAI(temperature=0, model_name="gpt-3.5-turbo", openai_api_key=os.getenv("OPENAI_API_KEY"))
qa = RetrievalQA.from_chain_type(llm=llm, retriever=db.as_retriever())

# å¿œç­”å‡¦ç†
if query:
    with st.spinner("è€ƒãˆä¸­..."):
        result = qa.invoke({"query": query})
        st.success(result["result"])
