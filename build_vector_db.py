from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from dotenv import load_dotenv
import os

# .env ã‹ã‚‰ OPENAI_API_KEY ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# Markdownãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
loader = DirectoryLoader(
    "lanet_data",
    glob="**/*.txt",
    loader_cls=lambda path: TextLoader(path, encoding="utf-8")
)
docs = loader.load()
print(f"ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(docs)}")

# ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
split_docs = splitter.split_documents(docs)
print(f"âœ‚ï¸ åˆ†å‰²å¾Œãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(split_docs)}")

# OpenAI åŸ‹ã‚è¾¼ã¿ + Chromaã¸ä¿å­˜
embedding = OpenAIEmbeddings(openai_api_key=os.getenv("OPENAI_API_KEY"))
db = Chroma.from_documents(split_docs, embedding, persist_directory="lanet_chroma_md")

print("âœ… ãƒ™ã‚¯ãƒˆãƒ«DBä½œæˆå®Œäº†ï¼ˆMarkdownå¯¾å¿œï¼‰")
